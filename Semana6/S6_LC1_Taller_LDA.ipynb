{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div >\n",
    "<img src = \"figs/ans_banner_1920x200.png\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caso-taller:  Recomendando el Blog de  Hernán Casciari \n",
    "\n",
    "\n",
    "[Hernán Casciari](https://hernancasciari.com/#bio), es un escritor argentino, que escribe blog posts con cuentos e historias  relacionadas con el futbol, su vida, infancia, y relaciones familiares con toques de ficción. Este [blog](https://hernancasciari.com/blog/) es  tan interesantes que en 2005 fue premiado como “El mejor blog del mundo” por Deutsche Welle de Alemania. \n",
    "\n",
    "El objetivo de este caso-taller es construir un sistema de recomendación basado en los contenidos de los posts utilizando similitud de las palabras usadas o temas de los cuentos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrucciones generales\n",
    "\n",
    "1. Para desarrollar el *cuaderno*, primero debe descargarlo.\n",
    "\n",
    "2. Para responder cada inciso deberá utilizar el espacio debidamente especificado.\n",
    "\n",
    "3. La actividad será calificada sólo si sube el *cuaderno* de jupyter notebook con extensión `.ipynb` en la actividad designada como \"entrega calificada por el personal\".\n",
    "\n",
    "4. El archivo entregado debe poder ser ejecutado localmente por el tutor. Sea cuidadoso con la especificación de la ubicación de los archivos de soporte, guarde la carpeta de datos en el mismo `path` de su cuaderno, por ejemplo: `data`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desarrollo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Carga de datos \n",
    "\n",
    "En la carpeta `data` se encuentran el archivo `blog_casciari.csv` con el título, la fecha de publicación, y el contenido de los cuentos publicados en el blog  de sr. Casciari. Cargue estos datos en su *cuaderno* y reporte brevemente el contenido de la base.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27a93734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       titulo    fecha  \\\n",
      "0            El rincón blanco  1/11/08   \n",
      "1  Mínimos avances en la cama  1/24/08   \n",
      "2                  Don Marcos  2/19/08   \n",
      "3              Los dos rulfos  3/26/08   \n",
      "4   La noticia no es el perro  4/15/08   \n",
      "\n",
      "                                              cuento  \n",
      "0  De pronto yo estaba en el hogar donde pasé la ...  \n",
      "1  Menos la cama, todo ha mejorado en este mundo....  \n",
      "2  Dos veces, y no una, mi abuelo materno me ayud...  \n",
      "3  A su regreso de México, mi amigo Comequechu no...  \n",
      "4  De repente, un video de You Tube recibe un mil...  \n",
      "La estructura del dataframe es de dimensión (520, 3)\n",
      "La venganza del metegol\n",
      "El mes pasado me invitaron a presentar un libro en Buenos Aires. Y como era un libro sobre fútbol, al final de la charla el director de la editorial nos invitó a jugar un partido de metegol (ese invento español al que sus creadores llaman, erróneamente, futbolín). Hacía años que no jugaba al metegol, pero por suerte me tocó de compañero un filósofo muy prestigioso y pudimos ganar. Nuestros contrincantes eran el autor del libro y el director de la editorial. De los tres, a este último lo conocía desde la juventud.\n",
      "Jugamos dos partidos enteros y los destrozamos con una facilidad pasmosa: hacía años que no practicaba este falso deporte de muñecas y reflejos, pero descubrí que no había perdido las mañas. Eso me hizo sentir bien: a mi edad cualquier destreza que mantengamos indemne, por más pelotuda que sea, se convierte en una gran noticia.\n",
      "Después de la charla algunos fotógrafos hicieron imágenes del partido de metegol y las subieron a Twitter.\n",
      "— Estadio: Librería Gandhi, Buenos Aires. Locales: A la izquierda, Alejandro Duchini y Gonzalo Garcés. Vistantes: A la derecha, Tomás Abraham y Hernán Casciari. Resultado: 1º match: 1-4; 2º match 0-4. Paliza.\n",
      "Cuando volví a casa recibí un mail de Chiri, mi mejor amigo desde la infancia. Me decía que había visto las fotos y se sorprendía de que mi compañero haya sido el mismo filósofo al que admirábamos en la juventud. «Vos, jugando al metegol con Tomás Abraham; solamente puede pasar en un sueño», me decía. Y era verdad. En un momento, durante el partido, me imaginé con diecisiete años mirando por la ventana de la librería Gandhi esa escena del futuro, y sonreí.\n",
      "Ese recuerdo momentáneo me desconcentró del juego y justo en ese momento me hicieron un gol (el único que recibí esa noche; yo defendía la zaga). Fue un gol con molinete de Gonzalo Garcés, el director de la editorial Galerna, y él, con injusticia, me lo festejó en la cara de un modo muy antideportivo, como si se tratara de la final del mundo.\n",
      "Entonces me vino a la cabeza algo que ya conté muchas veces en sobremesas con amigos, y que ocurrió la noche en que lo conocí a Gonzalo, cuando los dos éramos adolescentes.\n",
      "En ese entonces (sería el año noventa y uno) me gustaba mucho pasar los veranos en Mercedes, mi pueblo, porque mis padres se iban de vacaciones y me dejaban la casa sola. Mi amigo Chiri llegaba los viernes muy de madrugada, y pasaba por casa para ver si yo estaba despierto. Si veía luz en la habitación me tocaba timbre y nos emborrachábamos por ahí. Si no veía luz, entraba por la ventana de mi cuarto a oscuras y me despertaba de maneras horribles: a veces me tiraba agua en la cara, o me pegaba una patada en la panza. O me metía un gato entre las cobijas. O se subía arriba de las mantas y empezaba a bombearme desde atrás como un amante desenfrenado. El objetivo era despertarme siempre de una manera creativa.\n",
      "Pero cierto fin de semana pasó que, por la tarde, conocí a Gonzalo Garcés (que entonces era una promesa de escritor de diecisiete años) y lo invité a pasar un fin de semana a Mercedes. Gonzalo ya era entonces el cachorro de lo que es hoy: una persona fina, siempre muy bien bañado, de clase acomodada y sereno. De hecho, se había convertido un año antes, a los dieciséis, en el crítico literario más joven en la historia del diario porteño La Nación. Un prodigio, Garcés. Siempre lo fue.\n",
      "Nos conocimos por casualidad porque aquel año integramos una antología de «jóvenes promesas literarias» de entonces, y se había publicado un libro con veinte autores adolescentes. Yo leí su cuento y fue el único que me gustó, entonces lo llamé por teléfono y lo invité a casa para charlar. Estuvo en Mercedes ese fin de semana. Lo llevé al carnaval del pueblo, que es uno de los carnavales menos luminosos y más tristes de la provincia de Buenos Aires.\n",
      "La pasamos muy bien todo ese día, hasta el accidente nocturno. Gonzalo Garcés se quedó a dormir en casa y le ofrecí mi habitación. Yo me fui a dormir la borrachera a la cama de mis padres, sin recordar la rutina de Chiri por las madrugadas. Esa noche Gonzalo, un chico buen mozo y frágil, se acostó y apagó la luz en una ciudad desconocida de la llanura pampeana, y se quedó dormido, sin saber que en medio de la noche un borracho joven entraría a oscuras por la ventana y se subiría encima suyo para sodomizarlo.\n",
      "Yo no escuché el grito, porque la habitación de mis padres quedaba lejos. No me enteré de nada. Pero a la mañana siguiente encontré a Gonzalo en la cocina. Desayunaba con los pelos alborotados. Me dijo:\n",
      "—?Ayer entró un tipo por la ventana y me quiso fornicar. Yo estaba adentro de las sábanas y cuando saqué la cabeza, asustado, el tipo me mira y me dice «Vos no sos el gordo», y me deja de fornicar. Se levanta de la cama, me pide disculpas y se escapa por la ventana. Iba en un ciclomotor de la marca Zanella. No apareció nunca más.\n",
      "Yo miré la taza de café que tenía Gonzalo en la mano: le temblaba. Antes de que se pusiera a llorar lo tranquilicé:\n",
      "— Estamos en carnaval?—?le dije?—?. En estas épocas vale todo, Gonzalo.\n",
      "El susto de Garcés fue enorme, y yo creí siempre que se había olvidado de aquello. En esa época me preocupé más por el susto de mi amigo Chiri, que duró muchos años y fue traumático. Creer que estás violando en chiste a un amigo gordo, de toda la vida, y ver de repente que estás violando en chiste a una promesa literaria menor de edad, es horrible. Esa imagen no se va muy fácil del subconsciente. Pobre Chiri.\n",
      "Con el paso de los años fue peor, porque Gonzalo Garcés empezó a crecer en el mundo hispanoamericano de las letras, se convirtió en un gran escritor, en un crítico implacable, en el director de una editorial prestigiosa, y el trauma de Chiri creció siempre a la par de la consagración de Garcés.\n",
      "Hace unos años, cuando Gonzalo ganó el Premio Seix Barral, Chiri sintió mucha vergüenza por haber violado en la oscuridad a alguien que había conseguido el mismo galardón que Vargas Llosa.\n",
      "Pero ahora creo que el gol que me gritó Gonzalo Garcés a la cara durante el metegol, con una mirada maradoniana y vengativa que jamás le había visto antes, casi mirando a cámara, fue una manera de decirme que todavía se acuerda, que algo sigue roto en su alma, que no le gustaron mucho los carnavales de mi pueblo.\n",
      "Hernán Casciari\n",
      "17 noviembre, 2015\n"
     ]
    }
   ],
   "source": [
    "# Utilice este espacio para escribir el código.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Convertir el csv a un dataframe usando pandas\n",
    "casciari = pd.read_csv(\"data/blog_casciari.csv\", sep = \",\")\n",
    "\n",
    "# Ilustrar la esturctura del dataframe\n",
    "print(casciari.head())\n",
    "# Exploramos la estructura del dataframe\n",
    "print(\"La estructura del dataframe es de dimensión\", casciari.shape)\n",
    "\n",
    "# Vemos el cuento ejemplo - 160 La venganza del metegol\n",
    "#example=casciari['cuento'][160]\n",
    "print(casciari['titulo'][160])\n",
    "print(casciari['cuento'][160])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4e5e79",
   "metadata": {},
   "source": [
    "#### Procedimiento:\n",
    "\n",
    "1. Importamos las librerias a utilizar, en este caso son pandas y numpy\n",
    "2. Convertimos el archivo csv a un dataframe utilizando pandas\n",
    "3. Exploramos la estructura del dataframe\n",
    "4. Usamos la función shape para visualizar las dimensiones del dataframe\n",
    "\n",
    "#### Análisis y conclusiones: \n",
    "\n",
    "Podemos ver que el Blog de Hernán Casciri contiene 520 entradas y el archivo nos provee la información de título y fecha y cuento. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060d3c5e",
   "metadata": {},
   "source": [
    "### 2. Homogenización de textos\n",
    "\n",
    "Para cumplir con el objetivo de generar recomendaciones en esta sección debe preparar los posts para poder ser utilizados en su sistema de recomendación. Para ello, \"limpie\" y \"tokenize\" cada uno de los cuentos, describiendo detalladamente los pasos que realizo y si transformó o eliminó ciertas palabras. Para asistirlo en la tarea he creado listas de *stopwords* que están disponibles en la carpeta `data`. En su procedimiento ilustre la limpieza con el cuento 'La venganza del metegol'. (En su limpieza recuerde que el objetivo es generar recomendaciones a partir de la similitud de las palabras o temas de los cuentos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f78e58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mes invitar presentar aires futbol charla director editorial invito jugar partido metegol invento espanol creador llamar erroneamente futbolin ano jugar metegol suerte tocar companero filosofo prestigioso poder ganar contrincante autor director editorial conocio juventud jugamos partido entero destrozamos facilidad pasmós ano practicar falso deporte muneca reflejo descubri perdido mana sentir edad destreza mantengamos indemne pelotuda convertir noticia char fotografo imagen partido metegol subir twitter estadio librerio gandhi air local izquierdo duchini gonzalo garz vistant derecho tomar abraham resultado match      match      palizar volvi recibir mail amigo infancia decio visto foto sorprendia companero filosofo admirabar juventud jugar metegol toma abraham pasar sueno decia partido imaginar diecisiete ano mirar ventana librerio gandhi escenar futuro sonrei recuerdo momentaneo desconcentro juego justo gol unico recibi defendia zago gol molinete gonzalo garz director editorial galerno injusticia festejo cara antideportivo tratar venir cabeza conte sobremesa amigo ocurrio conoci gonzalo adolescente serio ano noventa gustar pasar veranos mercedes pueblo padre vacación dejar amigo llegar viernes madrugada pasar despierto veiar luz habitacion tocar timbre emborrachabamo veiar luz entrar ventana cuarto oscura despertar manera horrible tirar agua caro pegar patado panza metia gato cobija subio manta empezar bombearme amante desenfrenado objetivo despertarme creativo paso conoci gonzalo garz promés escritor diecisiete ano invitir pasar merced gonzalo cachorro persona fino banado clase acomodado sereno convertido ano dieciseis critico literario joven historia diario porteno nacion prodigio garz conocer casualidad ano integramo antologia joven promesa literario publicado veinte autor adolescente lei cuento unico gusto llame telefono invitar charlar merced lleve carnaval pueblo carnaval luminoso triste provincia aires pasar accidente nocturno gonzalo garz quedo dormir ofreci habitacion dormir borrachera cama padr recordar rutina madrugada gonzalo chico mozo fragil acosto apago luz ciudad desconocido llanura pampeán quedo dormido borracho joven entrario oscuro ventán subirio sodomizar escuche grito habitacion padre quedar lejos enterar manán encontre gonzalo cocina desayunar pelo alborotado ayer entro tipo ventana querer fornicar adentro sabana sacar cabeza asustado tipo mirar dejar fornicar levanta cama pedir disculpa escapa ventán ciclomotor marca zanella aparecio mire taza cafe tenia gonzalo mano temblar poner llorar tranquilizar carnaval epoca valer gonzalo susto garz enorme crei olvidado epoca preocupe susto amigo duro ano traumatico creer violar chiste amigo violar chiste promesa literario menor edad horrible imagen facil subconsciente pobre paso ano gonzalo garz empezo crecer hispanoamericano letra convirtio escritor critico implacable director editorial prestigioso trauma crecio par consagracion garz ano gonzalo gano premio seix barral sintio verguenzo violado oscuridad conseguido galardon vargas llosa gol grito gonzalo garz cara metegol mirada maradonián vengativo jama visto mirar camara decir acuerda roto alma gustar carnaval pueblo     noviembre\n"
     ]
    }
   ],
   "source": [
    "# Cargamos las librerías a utilizar\n",
    "import spacy\n",
    "import unidecode\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar el modelo para el idioma deseado \n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "\n",
    "## Agregamos las palabras de stopwords\n",
    "\n",
    "# Cargamos las stopwords extra\n",
    "extra_stopwords = pd.read_csv('data/stopwords_taller.csv', sep=',',header=None)\n",
    "extra_stopwords.columns = ['stopwords']\n",
    "extra_stopwords=set(extra_stopwords['stopwords'].to_list())\n",
    "\n",
    "# Agregamos a nuestro modelo de SpaCy\n",
    "nlp.Defaults.stop_words |= extra_stopwords\n",
    "\n",
    "## Creamos la función que limpie por completo el texto de los cuentos (Basado en el taller)\n",
    "\n",
    "def text_cleaning(txt):\n",
    "    \n",
    "    # Eliminar caracteres especiales\n",
    "    # Aplicar unidecode para eliminar las tildes\n",
    "    out = unidecode.unidecode(txt)    \n",
    "    # Eliminar caracteres no deseados, números y espacios en blanco adicionales\n",
    "    out = re.sub('[^A-Za-z0-9 ]+', ' ', out)\n",
    "    # Eliminar espacios extras\n",
    "    out = re.sub('\\s+', ' ', out)    \n",
    "    # Quitar números\n",
    "    out = re.sub(\"\\d+\", \"\", out)    \n",
    "    # Quitar espacios en blanco al principio y al final del texto\n",
    "    out = out.strip()\n",
    "    # Poner en minúsculas\n",
    "    out = out.lower()\n",
    "    #NLP object\n",
    "    out = nlp(out)\n",
    "    # Eliminar Stopwords\n",
    "    out = [token.text for token in out if not token.is_stop]\n",
    "    out = \" \".join(out)\n",
    "    # Obtener los lemas de cada palabra\n",
    "    lemmas =[token.lemma_ for token in nlp(out)]\n",
    "    # Convertir la lista de lemmas nuevamente a texto\n",
    "    out = \" \".join(lemmas)\n",
    "    # Remover palabras muy cortas\n",
    "    out = [token.text for token in nlp(out) if len(token) > 2]\n",
    "    \n",
    "    return out\n",
    "\n",
    "## Se corre la función de limpieza:\n",
    "\n",
    "clean = list(map(text_cleaning, casciari['cuento']))\n",
    "\n",
    "# Unimos las tokens\n",
    "clean_sentences = [\" \".join(i) for i in clean]\n",
    "\n",
    "# Vemos el cuento de la venganza del metegol\n",
    "print(clean_sentences[160])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2afef8b",
   "metadata": {},
   "source": [
    "#### Procedimiento:\n",
    "\n",
    "1. Se procede a cargar el modulo del idioma a usar \"es_core_news_sm\"\n",
    "2. Se agregan las palabras de stopwords a ese modulo\n",
    "3. Se crea una función que aplique sobre el dataframe para que realice la limpieza correspondiente.\n",
    "4. Se aplica la función sobre el dataframe.\n",
    "\n",
    "#### Análisis y conclusiones: \n",
    "\n",
    "Como se puede observar el texto limpio a diferencia del original se encuentra más resumido y se han retirado varias palabras conectoras junto con caracteres que no se usan (cmo tildes y ñ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2712a07c",
   "metadata": {},
   "source": [
    "### 3. Generando Recomendaciones\n",
    "\n",
    "En esta sección nos interesa generar recomendaciones de cuentos en el blog a un usuario que leyó 'La venganza del metegol'. Para ello vamos a utilizar distintas estrategias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54c4e35",
   "metadata": {},
   "source": [
    "#### 3.1. Recomendaciones basadas en contenidos\n",
    "\n",
    "##### 3.1.1. Genere 5 recomendaciones de más recomendada (1) a menos recomendada (5) para el cuento 'La venganza del metegol' usando en la distancia de coseno donde el texto este vectorizado por `CountVectorizer`. Explique el procedimiento que realizó y como ordenó las recomendaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "add22d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<520x31439 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 135006 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Utilice este espacio para escribir el código.\n",
    "\n",
    "## Comenzamos el proceso de Vectorización\n",
    "\n",
    "# Import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#Definimos un objeto CountVectorizer y creamos los vectores\n",
    "count = CountVectorizer(stop_words=list(nlp.Defaults.stop_words))\n",
    "count_matrix = count.fit_transform(casciari['cuento'])\n",
    "count_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dade17a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.05763125, 0.15401401, ..., 0.0297982 , 0.0791539 ,\n",
       "        0.11313072],\n",
       "       [0.05763125, 1.        , 0.10073516, ..., 0.11650663, 0.05704705,\n",
       "        0.07058373],\n",
       "       [0.15401401, 0.10073516, 1.        , ..., 0.09169374, 0.08498724,\n",
       "        0.13918667],\n",
       "       ...,\n",
       "       [0.0297982 , 0.11650663, 0.09169374, ..., 1.        , 0.05247855,\n",
       "        0.0346942 ],\n",
       "       [0.0791539 , 0.05704705, 0.08498724, ..., 0.05247855, 1.        ,\n",
       "        0.11506151],\n",
       "       [0.11313072, 0.07058373, 0.13918667, ..., 0.0346942 , 0.11506151,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importamos la función \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#Calculamos la matriz de similitud de coseno\n",
    "cosine_sim2 = cosine_similarity(count_matrix, count_matrix)\n",
    "\n",
    "cosine_sim2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cb01b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titulo</th>\n",
       "      <th>fecha</th>\n",
       "      <th>cuento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>El rincón blanco</td>\n",
       "      <td>1/11/08</td>\n",
       "      <td>De pronto yo estaba en el hogar donde pasé la ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             titulo    fecha  \\\n",
       "0  El rincón blanco  1/11/08   \n",
       "\n",
       "                                              cuento  \n",
       "0  De pronto yo estaba en el hogar donde pasé la ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "casciari.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb6fb6c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17                       Cuento con bruja y tramontina\n",
       "159                         Pajaritos en jaula gigante\n",
       "519                   La madre de todas las desgracias\n",
       "5                            El milagro de los pueblos\n",
       "138    Nueve libros que me hicieron olvidar el Mundial\n",
       "Name: titulo, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Se crea función de recomendador de cuentos\n",
    "\n",
    "def recomendador(title, cosine_sim=cosine_sim2, df=casciari):\n",
    "    \n",
    "    #Paso 2\n",
    "    df = df.reset_index()\n",
    "    indices = pd.Series(df.index, index=df['titulo']).drop_duplicates()\n",
    "    #Paso 3\n",
    "    idx = indices[title]\n",
    "\n",
    "    #Paso 4\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    #Paso 5\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    #Paso 6\n",
    "    sim_scores = sim_scores[1:6]\n",
    "\n",
    "    cuento_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    #Paso 7\n",
    "    return casciari['titulo'].iloc[cuento_indices]\n",
    "\n",
    "\n",
    "## Se aplica con CountVector\n",
    "\n",
    "recom=recomendador('La venganza del metegol', cosine_sim=cosine_sim2, df=casciari)\n",
    "recom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b29fc2e",
   "metadata": {},
   "source": [
    "#### Procedimiento:\n",
    "\n",
    "1. Se importaron las librerías necesarias para realizar la labor.\n",
    "2. Se uso CountVectorizer para definir un objeto y crear una matriz de conteo (count_matrix) de los textos de los cuentos en casciari.\n",
    "3. Se calculo la matriz de similitud de coseno (cosine_sim2) utilizando la matriz de conteo generada previamente.\n",
    "4. Se creo la función de recomendación\n",
    "5. Se creo una función de recomendación en la que se calculan los puntajes de similitud entre los cuentos de entrada y los demás, se ordena este puntaje de mayor a menor, se seleccionan los 5 mejores y se devuelve los titulos de los 5 mejores aplicando la matriz de similitud recomendada.\n",
    "6. Se aplico la función.\n",
    "\n",
    "#### Análisis y conclusiones: \n",
    "\n",
    "Luego de aplicar la función `recomendador` se obtuvo que las cinco recomendaciones son los títulos 17, 159, 519, 5 y 138."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e507761",
   "metadata": {},
   "source": [
    "##### 3.1.2. Genere 5 recomendaciones de más recomendada (1) a menos recomendada (5) para  el cuento 'La venganza del metegol' usando nuevamente la distancia de coseno, pero ahora vectorice el texto usando `TF-IDFVectorizer`. Explique el procedimiento que realizó y como ordenó las recomendaciones. Compare con los resultados del punto anterior y explique sus similitudes y/o diferencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9deeab0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aamir</th>\n",
       "      <th>abacaaado</th>\n",
       "      <th>abajo</th>\n",
       "      <th>abalanzar</th>\n",
       "      <th>abalanzo</th>\n",
       "      <th>abananado</th>\n",
       "      <th>abandonado</th>\n",
       "      <th>abandonar</th>\n",
       "      <th>abandono</th>\n",
       "      <th>abandón</th>\n",
       "      <th>...</th>\n",
       "      <th>zumbar</th>\n",
       "      <th>zumbido</th>\n",
       "      <th>zumr</th>\n",
       "      <th>zurda</th>\n",
       "      <th>zurdazo</th>\n",
       "      <th>zurdito</th>\n",
       "      <th>zurdo</th>\n",
       "      <th>zurraba</th>\n",
       "      <th>zurrar</th>\n",
       "      <th>zurrartir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24633 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aamir  abacaaado     abajo  abalanzar  abalanzo  abananado  abandonado  \\\n",
       "0    0.0        0.0  0.000000        0.0       0.0        0.0         0.0   \n",
       "1    0.0        0.0  0.023709        0.0       0.0        0.0         0.0   \n",
       "2    0.0        0.0  0.016429        0.0       0.0        0.0         0.0   \n",
       "3    0.0        0.0  0.000000        0.0       0.0        0.0         0.0   \n",
       "4    0.0        0.0  0.000000        0.0       0.0        0.0         0.0   \n",
       "\n",
       "   abandonar  abandono  abandón  ...  zumbar  zumbido  zumr  zurda  zurdazo  \\\n",
       "0        0.0       0.0      0.0  ...     0.0      0.0   0.0    0.0      0.0   \n",
       "1        0.0       0.0      0.0  ...     0.0      0.0   0.0    0.0      0.0   \n",
       "2        0.0       0.0      0.0  ...     0.0      0.0   0.0    0.0      0.0   \n",
       "3        0.0       0.0      0.0  ...     0.0      0.0   0.0    0.0      0.0   \n",
       "4        0.0       0.0      0.0  ...     0.0      0.0   0.0    0.0      0.0   \n",
       "\n",
       "   zurdito  zurdo  zurraba  zurrar  zurrartir  \n",
       "0      0.0    0.0      0.0     0.0        0.0  \n",
       "1      0.0    0.0      0.0     0.0        0.0  \n",
       "2      0.0    0.0      0.0     0.0        0.0  \n",
       "3      0.0    0.0      0.0     0.0        0.0  \n",
       "4      0.0    0.0      0.0     0.0        0.0  \n",
       "\n",
       "[5 rows x 24633 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Utilice este espacio para escribir el código.\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Definimos el objeto TF-IDF Vectorizer Object\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "#Construimos la matriz TF-IDF\n",
    "tfidf_matrix = tfidf.fit_transform(clean_sentences)\n",
    "\n",
    "#Dimensiones de la matriz\n",
    "tfidf_matrix.shape\n",
    "\n",
    "# Convertir la matriz dispersa a un DataFramem con el el vocabulario (palabras) que el TfidfVectorizer está utilizando\n",
    "df_tfidf = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf.get_feature_names_out())\n",
    "\n",
    "# Ver las primeras filas del  DataFrame resultante con la matriz TF-IDF y las palabras del vocabulario\n",
    "df_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb19d971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aamir</th>\n",
       "      <th>abacaaado</th>\n",
       "      <th>abajo</th>\n",
       "      <th>abalanzar</th>\n",
       "      <th>abalanzo</th>\n",
       "      <th>abananado</th>\n",
       "      <th>abandonar</th>\n",
       "      <th>abandón</th>\n",
       "      <th>abanico</th>\n",
       "      <th>abaraja</th>\n",
       "      <th>...</th>\n",
       "      <th>zumbadisir</th>\n",
       "      <th>zumbar</th>\n",
       "      <th>zumr</th>\n",
       "      <th>zurda</th>\n",
       "      <th>zurdazo</th>\n",
       "      <th>zurdito</th>\n",
       "      <th>zurdo</th>\n",
       "      <th>zurraba</th>\n",
       "      <th>zurrar</th>\n",
       "      <th>zurrartir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24630 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aamir  abacaaado     abajo  abalanzar  abalanzo  abananado  abandonar  \\\n",
       "0    0.0        0.0  0.000000        0.0       0.0        0.0        0.0   \n",
       "1    0.0        0.0  0.023709        0.0       0.0        0.0        0.0   \n",
       "2    0.0        0.0  0.016429        0.0       0.0        0.0        0.0   \n",
       "3    0.0        0.0  0.000000        0.0       0.0        0.0        0.0   \n",
       "4    0.0        0.0  0.000000        0.0       0.0        0.0        0.0   \n",
       "\n",
       "   abandón  abanico  abaraja  ...  zumbadisir  zumbar  zumr  zurda  zurdazo  \\\n",
       "0      0.0      0.0      0.0  ...         0.0     0.0   0.0    0.0      0.0   \n",
       "1      0.0      0.0      0.0  ...         0.0     0.0   0.0    0.0      0.0   \n",
       "2      0.0      0.0      0.0  ...         0.0     0.0   0.0    0.0      0.0   \n",
       "3      0.0      0.0      0.0  ...         0.0     0.0   0.0    0.0      0.0   \n",
       "4      0.0      0.0      0.0  ...         0.0     0.0   0.0    0.0      0.0   \n",
       "\n",
       "   zurdito  zurdo  zurraba  zurrar  zurrartir  \n",
       "0      0.0    0.0      0.0     0.0        0.0  \n",
       "1      0.0    0.0      0.0     0.0        0.0  \n",
       "2      0.0    0.0      0.0     0.0        0.0  \n",
       "3      0.0    0.0      0.0     0.0        0.0  \n",
       "4      0.0    0.0      0.0     0.0        0.0  \n",
       "\n",
       "[5 rows x 24630 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Como se ve existen palabras que no quedaron bien lematizadas se procede a crear un lematizador\n",
    "\n",
    "# Lematizador propio\n",
    "def Lematizador_propio(text):\n",
    "    # Diccionario con las palabras y sus lemas correspondientes\n",
    "    lemmas = {\n",
    "        r\"\\babandona\\b\": \"abandonar\",\n",
    "        r\"\\babandonado\\b\": \"abandonar\",\n",
    "        r\"\\babandonandolo\\b\": \"abandonar\",\n",
    "        r\"\\babandonar\\b\": \"abandonar\",\n",
    "        r\"\\babandono\\b\": \"abandonar\",\n",
    "        r\"\\bzumbido\\b\": \"zumbar\"\n",
    "    }\n",
    "\n",
    "    # Buscar y reemplazar las palabras usando expresiones regulares\n",
    "    for pattern, lemma in lemmas.items():\n",
    "        text = re.sub(pattern, lemma, text, flags=re.IGNORECASE)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Limpiamos nuestro texto con el lematizador propio\n",
    "clean_sentences2 = list(map(Lematizador_propio, clean_sentences))\n",
    "\n",
    "\n",
    "#Definimos el objeto TF-IDF Vectorizer Object\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "#Construimos la matriz TF-IDF\n",
    "tfidf_matrix = tfidf.fit_transform(clean_sentences2)\n",
    "\n",
    "# Examinamos la nueva matriz\n",
    "# Convertir la matriz dispersa a un DataFramem con el el vocabulario (palabras) que el TfidfVectorizer está utilizando\n",
    "df_tfidf = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf.get_feature_names_out())\n",
    "\n",
    "# Ver las primeras filas del  DataFrame resultante con la matriz TF-IDF y las palabras del vocabulario\n",
    "df_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be85ac6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos las funciones a utilizar\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# Calculamos el producto punto\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "544be8c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17                       Cuento con bruja y tramontina\n",
       "138    Nueve libros que me hicieron olvidar el Mundial\n",
       "5                            El milagro de los pueblos\n",
       "121                                      Gaussian blur\n",
       "519                   La madre de todas las desgracias\n",
       "Name: titulo, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recom=recomendador('La venganza del metegol', cosine_sim=cosine_sim, df=casciari)\n",
    "recom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a6b704",
   "metadata": {},
   "source": [
    "#### Procedimiento:\n",
    "\n",
    "\n",
    "#### Análisis y conclusiones: \n",
    "Luego de aplicar la función `recomendador` se obtuvo que las cinco recomendaciones son los títulos 17, 138, 5, 121 y 519. En contraste con el anterior recomendador se tiene que se mantienen los títulos 17, 519, 5 y 138."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead6289a",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1067c9a",
   "metadata": {},
   "source": [
    "##### 3.1.3. Genere 5 recomendaciones de más recomendada (1) a menos recomendada (5) para el cuento 'La venganza del metegol' usando el texto vectorizado por `TF-IDFVectorizer` y la correlación como medida de similitud. Explique el procedimiento que realizó y como ordenó las recomendaciones. Compare con los resultados de los puntos anteriores y explique sus similitudes y/o diferencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f8f20d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomendación 1: 17 - Cuento con bruja y tramontina\n",
      "Recomendación 2: 121 - Gaussian blur\n",
      "Recomendación 3: 14 - Dice el Chiri, dice el Gordo\n",
      "Recomendación 4: 414 - La desgracia venía en sobres papel madera\n",
      "Recomendación 5: 107 - Matar la crisis a volantazos\n"
     ]
    }
   ],
   "source": [
    "# Utilice este espacio para escribir el código.\n",
    "\n",
    "\n",
    "## Se vectoriza el texto de nuevo\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(casciari['cuento'])\n",
    "\n",
    "## Se cálcula la matriz de correlación\n",
    "correlation_matrix = pd.DataFrame(np.corrcoef(tfidf_matrix.toarray()))\n",
    "\n",
    "## Seleccionamos el cuento correspondiente\n",
    "cuento_seleccionado = 160\n",
    "\n",
    "## Obtenemos las recomendaciones excluyendo el cuento de metegol\n",
    "correlation_scores = correlation_matrix.iloc[cuento_seleccionado]\n",
    "correlation_scores[cuento_seleccionado] = 0  # Excluir el cuento de origen\n",
    "\n",
    "## Obtenemos las 5 mejores recomendaicones\n",
    "top_recommended_indices = correlation_scores.argsort()[::-1][:5]\n",
    "\n",
    "## Se muestra el resultado\n",
    "for i, idx in enumerate(top_recommended_indices):\n",
    "    print(f\"Recomendación {i + 1}: {idx} - {casciari['titulo'].iloc[idx]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3648b29",
   "metadata": {},
   "source": [
    "### Procedimiento\n",
    "\n",
    "### Análisis y Conclusiones\n",
    "Luego de aplicar la función `recomendador` se obtuvo que las cinco recomendaciones son los títulos 17, 121, 14, 414 y 107. En contraste con el anterior recomendador se tiene que se mantienen los títulos 17 y 121."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb8cc71",
   "metadata": {},
   "source": [
    "##### 3.2. Recomendaciones basadas en temas\n",
    "\n",
    "Usando modelado de temas con LDA, encuentre los temas subyacentes en el blog. Explique como eligió el numero óptimo de temas. Utilizando el tema asignado al cuento 'La venganza del metegol' y la probabilidad de pertenecer a este tema genere 5 recomendaciones de más recomendada (1) a menos recomendada (5) para este cuento. Explique el procedimiento que realizó. Compare con los resultados encontrados anteriormente y explique sus similitudes y/o diferencias. (Esto puede tomar mucho tiempo y requerir mucha capacidad computacional, puede aprovechar los recursos de [Google Colab](https://colab.research.google.com/))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ea55cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.corpora.dictionary.Dictionary at 0x279f860b880>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Utilice este espacio para escribir el código.\n",
    "\n",
    "## Se realizan lso siguientes pasos\n",
    "\n",
    "# Cargamos la función \n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Creamos la representación de diccionario del documento\n",
    "dictionary = Dictionary(clean)  ## Se toma el resultado de la primera limpieza\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250669cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Removemos palabras que aparecen en menos de 20 páginas o en más de 50%\n",
    "\n",
    "dictionary.filter_extremes(no_below=20, no_above=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6b23f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de palabras únicas: 308\n"
     ]
    }
   ],
   "source": [
    "## Creamos el corpus de la matriz de frecuencia del documento\n",
    "\n",
    "corpus = [dictionary.doc2bow(doc) for doc in clean]\n",
    "\n",
    "## imprimimos el número de palabras con las que estimaremos el LDA\n",
    "\n",
    "print('Numero de palabras únicas: %d' % len(dictionary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebbf85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cargamos la función \n",
    "\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "## Estimamos el modelo\n",
    "\n",
    "Estimacion = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=dictionary,\n",
    "    num_topics=3,\n",
    "    chunksize=1000,\n",
    "    passes=20,\n",
    "    iterations=400,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    random_state=123,\n",
    "    eval_every=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ea83a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.016*\"mujer\" + 0.012*\"llegar\" + 0.012*\"ver\" + 0.011*\"amigo\" + 0.009*\"loco\" '\n",
      "  '+ 0.009*\"haber\" + 0.009*\"mano\" + 0.009*\"pueblo\" + 0.009*\"tenia\" + '\n",
      "  '0.009*\"pensar\"'),\n",
      " (1,\n",
      "  '0.016*\"escribir\" + 0.015*\"argentino\" + 0.011*\"foto\" + 0.011*\"hombre\" + '\n",
      "  '0.010*\"llamar\" + 0.010*\"pensar\" + 0.009*\"amigo\" + 0.009*\"historia\" + '\n",
      "  '0.009*\"futbol\" + 0.009*\"tenia\"'),\n",
      " (2,\n",
      "  '0.028*\"caio\" + 0.021*\"viejo\" + 0.020*\"zacarias\" + 0.019*\"nacho\" + '\n",
      "  '0.019*\"sofi\" + 0.017*\"zacaria\" + 0.016*\"hijo\" + 0.014*\"chico\" + 0.012*\"ver\" '\n",
      "  '+ 0.012*\"llorar\"')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(Estimacion.print_topics())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d552d59",
   "metadata": {},
   "source": [
    "Vemos el peso de las diferentes palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c044b784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\anaconda3\\envs\\Financiero\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3397, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Felipe\\AppData\\Local\\Temp\\ipykernel_26236\\3300423467.py\", line 6, in <cell line: 6>\n",
      "    coherencemodel.get_coherence()\n",
      "  File \"c:\\Users\\Felipe\\anaconda3\\envs\\Financiero\\lib\\site-packages\\gensim\\models\\coherencemodel.py\", line 614, in get_coherence\n",
      "    confirmed_measures = self.get_coherence_per_topic()\n",
      "  File \"c:\\Users\\Felipe\\anaconda3\\envs\\Financiero\\lib\\site-packages\\gensim\\models\\coherencemodel.py\", line 574, in get_coherence_per_topic\n",
      "    self.estimate_probabilities(segmented_topics)\n",
      "  File \"c:\\Users\\Felipe\\anaconda3\\envs\\Financiero\\lib\\site-packages\\gensim\\models\\coherencemodel.py\", line 546, in estimate_probabilities\n",
      "    self._accumulator = self.measure.prob(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\anaconda3\\envs\\Financiero\\lib\\site-packages\\gensim\\topic_coherence\\probability_estimation.py\", line 156, in p_boolean_sliding_window\n",
      "    return accumulator.accumulate(texts, window_size)\n",
      "  File \"c:\\Users\\Felipe\\anaconda3\\envs\\Financiero\\lib\\site-packages\\gensim\\topic_coherence\\text_analysis.py\", line 446, in accumulate\n",
      "    return self.merge_accumulators(accumulators)\n",
      "  File \"c:\\Users\\Felipe\\anaconda3\\envs\\Financiero\\lib\\site-packages\\gensim\\topic_coherence\\text_analysis.py\", line 541, in merge_accumulators\n",
      "    accumulator.merge(other_accumulator)\n",
      "  File \"c:\\Users\\Felipe\\anaconda3\\envs\\Financiero\\lib\\site-packages\\gensim\\topic_coherence\\text_analysis.py\", line 400, in merge\n",
      "    self._co_occurrences += other._co_occurrences\n",
      "  File \"c:\\Users\\Felipe\\anaconda3\\envs\\Financiero\\lib\\site-packages\\scipy\\sparse\\lil.py\", line 132, in __iadd__\n",
      "TypeError: unsupported operand type(s) for +: 'lil_matrix' and 'lil_matrix'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\anaconda3\\envs\\Financiero\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 1992, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"c:\\Users\\Felipe\\anaconda3\\envs\\Financiero\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1118, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"c:\\Users\\Felipe\\anaconda3\\envs\\Financiero\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1012, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"c:\\Users\\Felipe\\anaconda3\\envs\\Financiero\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 865, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"c:\\Users\\Felipe\\anaconda3\\envs\\Financiero\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 818, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"c:\\Users\\Felipe\\anaconda3\\envs\\Financiero\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 736, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"c:\\Users\\Felipe\\anaconda3\\envs\\Financiero\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\Felipe\\anaconda3\\envs\\Financiero\\lib\\site-packages\\stack_data\\core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"c:\\Users\\Felipe\\anaconda3\\envs\\Financiero\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\Felipe\\anaconda3\\envs\\Financiero\\lib\\site-packages\\stack_data\\core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"c:\\Users\\Felipe\\anaconda3\\envs\\Financiero\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\Felipe\\anaconda3\\envs\\Financiero\\lib\\site-packages\\stack_data\\core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"c:\\Users\\Felipe\\anaconda3\\envs\\Financiero\\lib\\site-packages\\executing\\executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "## Se empieza el proceso para elegir el número de temas\n",
    "\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "coherencemodel = CoherenceModel(model=Estimacion, texts=clean, dictionary=dictionary)\n",
    "coherencemodel.get_coherence() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7c9b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "\n",
    "def calcular_coherencia(dictionary, corpus, texts, start=1, limit=10, step=1):\n",
    " \n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    \n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = LdaMulticore(corpus=corpus,\n",
    "                        id2word=dictionary,\n",
    "                        num_topics=num_topics, \n",
    "                        random_state=123,\n",
    "                        passes=20)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values\n",
    "\n",
    "modelos, valores_c = calcular_coherencia(dictionary=dictionary, corpus=corpus, texts=clean, start=1, limit=10, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523b3ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Se grafican los resultados\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Show graph\n",
    "limit=10; start=1; step=1;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, valores_c)\n",
    "plt.xlabel(\"Número de Temas\")\n",
    "plt.ylabel(\"Medida de Coherencia\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c86d4d9",
   "metadata": {},
   "source": [
    "Con base en estos resultados se elige el número de temas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898d3c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Se calcula la perplejidad\n",
    "np.exp2(-lda_model_opt.log_perplexity(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d7bf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Se crea una función \n",
    "\n",
    "def perplejidad_ntemas(dictionary, corpus, texts, start=1, limit=10, step=1):\n",
    " \n",
    "    perplejidad_values = []\n",
    "    model_list = []\n",
    "    \n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = LdaMulticore(corpus=corpus,\n",
    "                        id2word=dictionary,\n",
    "                        num_topics=num_topics, \n",
    "                        random_state=123,\n",
    "                        passes=20)\n",
    "        model_list.append(model)\n",
    "        perplejidad_values.append(np.exp2(-model.log_perplexity(corpus)))\n",
    "\n",
    "    return model_list, perplejidad_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538fc875",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Se modela y se gráfica\n",
    "modelos, valores_p = perplejidad_ntemas(dictionary=dictionary, corpus=corpus, texts=clean, start=1, limit=10, step=1)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Show graph\n",
    "limit=10; start=1; step=1;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, valores_p)\n",
    "plt.xlabel(\"Número de Temas\")\n",
    "plt.ylabel(\"Medida de Perplejidad\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a7b3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomendaciones para 'La venganza del metegol':\n",
      "Recomendación 1: Mínimos avances en la cama\n",
      "Recomendación 2: El rincón blanco\n"
     ]
    }
   ],
   "source": [
    "## Definido el número de temas se procede a correr el modelo\n",
    "\n",
    "# Probar diferentes números de temas\n",
    "num_topics = 20  # Ejemplo porque no me corre en mi equipo\n",
    "\n",
    "# Entrenar el modelo LDA\n",
    "lda_model = LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=15)\n",
    "\n",
    "# Obtener las asignaciones de temas para todos los cuentos\n",
    "topic_assignments = lda_model.get_document_topics(corpus)\n",
    "\n",
    "cuento_seleccionado = 'La venganza del metegol'\n",
    "\n",
    "# Obtén las asignaciones de temas para el cuento seleccionado\n",
    "temas_del_cuento = lda_model.get_document_topics(corpus[160])\n",
    "\n",
    "# Ordenar los cuentos por probabilidad de pertenecer al mismo tema\n",
    "cuentos_similares = sorted(enumerate(temas_del_cuento), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Obtener las 5 recomendaciones excluyendo el cuento de origen\n",
    "top_recomendaciones = [cuentos_similares[i][0] for i in range(1, len(cuentos_similares))]\n",
    "\n",
    "# Imprimir las recomendaciones\n",
    "print(\"Recomendaciones para 'La venganza del metegol':\")\n",
    "for i, idx in enumerate(top_recomendaciones):\n",
    "    print(f\"Recomendación {i + 1}: {casciari['titulo'].iloc[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Utilice este espacio para describir el procedimiento, análisis, y conclusiones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Recomendaciones generales\n",
    "\n",
    "De acuerdo con los resultados encontrados, en su opinión ¿qué procedimiento generó las mejores recomendaciones para la entrada elegida? ¿Cómo implementaría una evaluación objetiva de estas recomendaciones? Justifique su respuesta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Utilice este espacio para describir su procedimiento)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
